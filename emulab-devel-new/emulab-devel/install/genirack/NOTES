Setting up an InstaGeni Rack. First, we need the following info:

* We start here, after you have sent Utah "checklist", waiting for the
  images to be baked. Once you hear back from us, you may continue
  with these instructions.

  Waiting, waiting, waiting ...

* Power on the control switch (Procurve 2620 in the top slot).

* Attach a console to the control node and power on the node. You will
  wait a while for the "HP ProLiant" screen. Watch CAREFULLY, looking
  for the moment it says "press any key for Option ROM messages."
  Press any key!

  and then right after the screen
  switches, type F8 to get into the iLo configuration. Gotta be fast
  on this. If you miss it, power cycle. 

* Once the iLo screen comes up, right arrow to Network and choose the
  DHCP option. You want to make sure DHCP is off. F10 to save and then
  esc to go back. Then choose the NIC option. Fill in the iLo
  IP/Mask/Router, then F10 to save and then esc to exit. iLo will
  reset.

* Is the RAID array setup? It wasn't on Utah's rack. Need to fill this
  part in.

* At this point, Utah can do the rest of the rack setup without
  further intervention from you. Well, unless something gets wedged
  and Utah needs something to be physically power cycled. Or you can
  go back to your desk and proceed to setup the rack using the
  following instructions. Which do you prefer? I know you will make
  the correct choice.

* Now that you have decided, send email to Utah asking us to complete
  the installation while you go back to working on other projects. 

======================================================================

* Verify that the DNS records are being served properly from the
  parent domain.  For instance, if the rack is instageni.foo.edu, then
  try:

        $ host -t NS instageni.foo.edu
        instageni.foo.edu name server ns.instageni.foo.edu
        $ host -t A ns.instageni.foo.edu
        ns.instageni.foo.edu has address 123.123.123.123

  If you don't get positive responses to either query (if things are
  broken, then NXDOMAIN errors are a likely symptom), then stop and
  ask the local admin to fix it.

* Using your web browser, go to the iLo IP you set, and login using
  Administrator and the iLo password that is stamped on top of the
  control node, or in the data file you received. If using the
  datafile, look for the section that says:

	<u_location>U34</u_location>

  cause the control node is slot 34. Grab the lo_passwd from that
  section; that is you iLo password.

* In a shell window, you want to ssh over to the iLo:

	boss> ssh Administrator@iloIP

  This can be slow, so be patient. Once you get logged in, enter
  "textcons" at the command prompt. This will put you into a wacky
  text representation of the graphic console. To exit from the
  text console, use ESC-(

* Disable IPMI; When logged into the ilo web interface, go to
  Administration->Access Settings and uncheck the IPMI box. Be sure
  to click on apply.

* Go to the Virtual Media tab, and then on the right hand side specify
  the url of the boot ISO image. This will be something like:
  
	http://155.98.32.70/downloads/genirack.iso
	
  which is Utah's web server. Check the box to boot from the CD on the
  next reset. The click on "Insert Media", and then after you get the
  confirmation that it attached okay, click the reset button.
  
* Wait for the node to boot. It should boot from the virtual CD drive
  since there is no other boot media, but if not you can hit F11 on
  the next go around, which will give you a list of options. Type
  whatever number is to the left of the CD choice.  

* The ISO will load and give you a boot prompt. This takes a while.
  Just hit return. You will eventually get a shell prompt after a lot
  of noisy output. This can take several minutes since it is demand
  loading the "CD" from Utah's web server. Be patient.

* Fire up the network:

	ifconfig eth0 inet Control_IP netmask Control_Mask
	route add default gw Gateway_IP

  The Control_IP is *NOT* the iLo IP you used above. It is the IP you
  have assigned to the control node itself.

* Transfer the control node image from Utah:

	cd /tmp
	wget http://155.98.32.70/downloads/genirack-1.ndz

  This is about a 1GB so it will take a while.

* Write the image file to the disk using the Emulab decompression tool:

	/usr/bin/imageunzip -o genirack-1.ndz /dev/cciss/c0d0

  This will take a little while. Watch the dots. There is a pause at
  the end while buffers are flushed to disk. Be patient. 

* Set the boot order so that the control node does not try to boot
  from the network, unless all else fails.

	cd /TOOLKIT
	./setbootorder floppy cdrom usb hd pxe

* Type "reboot" at the shell prompt. With any luck, the node will boot
  first time and you can ssh into the control node as elabman. You
  will need to add the key from /root/.ssh/elabman_dsa to your ssh agent,
  and the pass phrase is in boss:/usr/testbed/etc/elabman_dsa.pswd


  * Make sure all five of the experimental nodes are fully powered off;
  the ilo has to be off, and the easiest thing to do is just unplug
  them.

  Also make sure that the serial cable is connected to the 2620.

* Connect to the 2620 using this command:

	sudo screen /dev/ttyS0 19200

  It might not do anything when you carriage return; it is trying to sync
  up the speed (the switch does auto-sense). Wait 30 seconds, hit carriage
  return a few times again. If still not working, exit from screen ("^A \")
  and try again. Might take another iteration or two. When you have the
  prompt: 

  2620> config
  2620(config)> vlan 11
  2620(vlan-11)> name control-alternate
  2620(vlan-11)> untagged 24        XXXX Make sure about port number!
  2620(vlan-11)> ip address 10.2.1.253/24
  2620(vlan-11)> exit
  2620(config)> vlan 10
  2620(vlan-10)> name control-hardware
  2620(vlan-10)> untagged 23	   XXXX Make sure about port number!
  2620(vlan-10)> ip address 10.1.1.253/24
  2620(vlan-10)> exit
  2620(config)> vlan 1
  2620(vlan-1)> ip address 10.254.254.253/24  # IGMP querier requires this
  2620(vlan-1)> exit
  2620(config)> management-vlan 10
  2620(config)> ip default-gateway 10.1.1.254
  2620(config)> vlan 1 ip igmp
  2620(config)> vlan 1 ip igmp querier
  2620(config)> no web-management
  2620(config)> no snmp-server community public
  2620(config)> snmp-server community XXXXX manager unrestricted
  2620(config)> password all (type in same password for manager/operator)
  2620(config)> write memory
  2620(config)> reload

  UTAH: THE PASSWORD and COMMUNITY string come from variables.txt file
  in the rack subdir. Use the same for both switches.

  The switch will take moment to reset so you might lose your connection
  to the control node.

  Ping 10.1.1.253 and 10.2.1.253 to make sure things worked okay.
  Then telnet to 10.1.1.253 and make sure you can login using the
  switch password.

* Have the local site admin move the console cable to the 5406.
  Wait, wait, wait. 

* Connect to the 5406 using this command:

	sudo screen /dev/ttyS0 115200

  It might not do anything when you carriage return; it is trying to sync
  up the speed (the switch does auto-sense). Wait 30 seconds, hit carriage
  return a few times again. If still not working, exit from screen ("^A \")
  and try again. Might take another iteration or two. When you have the
  prompt: 
  
  5400> config
  5400(config)> no vlan 1 ip address
  5400(config)> vlan 10
  5400(vlan-10)> name control-hardware
  5400(vlan-10)> untagged A20	  XXXX Make sure about port number! E20?
  5400(vlan-10)> ip address 10.3.1.253/24
  5400(vlan-10)> exit 
  5400(config)> management-vlan 10
  5400(config)> ip default-gateway 10.3.1.7
  5400(config)> no web-management
  5400(config)> no snmp-server community public
  5400(config)> snmp-server community XXXXX manager unrestricted
  5400(config)> password all (type in same password for manager/operator)
  5400(config)> write memory
  5400(config)> reload
  
  USE THE SAME PASSWORD and COMMUNITY XXXXX as above (2620)

  Wait for the switch to reboot and confirm you can telnet to 10.3.1.253
  and log in using the switch password. 
  
* Create the 4th partition in the partition table:

	sudo fdisk /dev/sda

  Use the "n" option, primary partition type, default start, default end, "w"
  to write it out.

  Then inform the kernel:

	sudo partprobe -s

* Initialize the LVM partition. We use LVMs for the boss/ops filesystems.

	sudo pvcreate /dev/sda4
	sudo vgcreate xen-vg /dev/sda4
    	sudo vgchange -a y xen-vg

* Create a filesystem to hold the boss/ops tarballs. These are pretty
  big but will be deleted after we copy the filesystems into their own
  lvms.

	sudo mkdir /scratch
	sudo /sbin/lvcreate -n scratch -L 75G xen-vg
	sudo mke2fs -j /dev/xen-vg/scratch
	sudo mount /dev/xen-vg/scratch /scratch
	sudo chmod 777 /scratch

* Copy the boss/ops tarfile to /scratch on the control node, and
  then unpack it. There will be two directories, ops and boss.

* Restore the VMs:

        mkdir ~elabman/boss ~elabman/ops
	sudo ~elabman/restorevm.pl -t ~elabman/boss boss /scratch/boss
	sudo ~elabman/restorevm.pl -t ~elabman/ops  ops /scratch/ops

  This creates a bunch of LVMs and rewrites the xm.conf in the
  boss/ops directories to reflect the new LVM paths, etc.

* Fire up the VMs. Ops has to be first, followed by boss.

	sudo xl create ~elabman/ops/xm.conf
	sleep 30
	sudo xl create ~elabman/boss/xm.conf

* It is possible that ops will hang on fixarp, because tmcd is not
  running on boss yet. Log into boss (as elabman) and do:

	sudo testbed-control boot

  which should get ops running.

* named setup does not handle reverse maps smaller then /24 cause of
  the delegation stuff. Needs to be defined as a partial map since
  that is what the upper subnet delegates. But we do not handle this
  in the named config scripts. So I had to edit /etc/namedb/named.conf
  and add this (edit IP of course) to both views. Be sure to delete the
  existing reverse zone (both views) since it is incorrect.

    zone "129/25.242.1.192.in-addr.arpa" in {
    	type master;
    	file "reverse/192.1.242.db";
    };

* Run named_setup. Tail /var/log/messages to look for errors.

	boss> named_setup

* Copy the openvpn certs from boss over to the control node.

	boss> scp -p /usr/testbed/etc/openvpn-server.pem elabman@control:openvpn
	boss> scp -p /usr/testbed/etc/openvpn-dh.pem elabman@control:openvpn
	boss> scp -p /usr/testbed/etc/emulab.pem elabman@control:openvpn

* Start the openvpn server on the control node.

	control> cd /etc/openvpn
	control> sudo ln -s ~elabman/openvpn/openvpn.conf emulab.conf
	control> sudo /etc/rc3.d/S16openvpn start

* Now it is time to power on the experimental nodes. If all goes well,
  they will boot up into FreeBSD MFS and be in the hwdown experiment.
  Before we release them, we want to change some settings on the ilo.
  The following will change the Admin password, create an elabman
  user, load its ssh key, change the boot order, etc, etc.

	sudo sh /usr/testbed/etc/initilo.sh

* The above command resets the ilo, so lets play the minute waltz, maybe
  twice.

	http://www.pianoparadise.com/downloadmp3/nocturne.wav

* Now you have to log into all of the consoles and change the BIOS
  so that the disk controller is SATA AHCI instead of the raid controller.

* Now we power on all of the nodes.

	sudo wap power on pc1 pc2 pc3 pc4 pc5

* If the nodes were actually off, it is going to take a couple of minutes
  before we can go on with the next step. Play the waltz a few more times.

* Free all the nodes up and lets hope they reload okay. Okay, lets
  just do one to start with.

	wap nfree emulab-ops hwdown pc1

  If that works and pc1 does indeed go into the free pool, then do the
  rest of the nodes:

  	wap nfree emulab-ops hwdown pc2 pc3 pc4 pc5

* Enable this site in Utah (run this on Utah Emulab boss).

	sudo cacontrol -c boss.XXX.XXX.XXX

* On the new boss, need to reload the bundles:

	sudo /usr/testbed/sbin/protogeni/getcacerts

* Arrange for the VMs to auto start (on the control node):

	cd /etc/xen/auto/
	sudo ln -s ~elabman/ops/xm.conf 1.ops.conf
	sudo ln -s ~elabman/boss/xm.conf 2.boss.conf

* Next we want to update the firmware on the data plane switch to the
  one that supports openflow. First copy the firmware from Utah to the
  local tftp directory on boss.

	cd /tftpboot
	sudo wget http://www.emulab.net/downloads/K_15_06_5008.swi

* Log into procurve2 using the password in /usr/testbed/etc/switch.pswd
  We then want to make a copy of the current config in case we have to
  revert back.

	5406> show config files
	5406> copy config config1 config config-save
       
* Now load the openflow firmware into the primary flash. First make
  sure the secondary has a copy of the primary. 

	5406> show flash
	5406> copy tftp flash 10.3.1.1 K_15_06_5008.swi

* And if that works, reboot the switch.

	5406> reload

* Wait for the switch to reboot, now lets see if snmpit works:

	boss> wap snmpit -l -l -O

  NOTE: You may see this warning:

	No such VLAN control-hardware in lans table

  No worries, you can ignore it.

* Copy root public ssh key to the tftp directory:

	boss> sudo cp /root/.ssh/id_rsa.pub /tftpboot

* Telnet to procurve1 (/usr/testbed/etc/switch.pswd):

	2629> config
	2620(config)> ip ssh
	2620(config)> aaa authentication ssh login public-key none
	2620(config)> aaa authentication ssh enable public-key none
	2620(config)> copy tftp pub-key-file 10.1.1.1 id_rsa.pub manager
        2620(config)> write memory

* Telnet to procurve2 (/usr/testbed/etc/switch.pswd):

	5400> config
        5400(config)> ip ssh
        5400(config)> aaa authentication ssh login public-key none
        5400(config)> aaa authentication ssh enable public-key none
        5400(config)> copy tftp pub-key-file 10.3.1.1 id_rsa.pub manager
	5400(config)> write memory

* Add the public IP space, if appropriate. See the site survey response.
  This needs to go into the image baking script.

	boss> wap addvpubaddr 192.1.242.150 192.1.242.179
	boss> wap addvpubaddr 192.1.242.190 192.1.242.250

* Run update_sitevars and addservers to get boss/ops into the DB
  and to turn on arp lockdown.

	boss> wap /usr/testbed/sbin/update_sitevars 
	boss> wap /usr/testbed/sbin/addservers

* Insert the firewall rules for the shared node pool:

	boss> cd emulab-devel/obj/firewall
	boss> gmake
	boss> gmake insertvars insertrules

* Create the shared-pool experiment. Use this NS file:

	testbed/install/genirack/shared-exp.ns

  You will need to toggle the lockdown on the Show Experiment page first,
  and then toggle it back after the experiment has swapped in. Be sure to
  test shared node experiments.

* Create an experiment that uses the shared nodes. Use this NS file.

	testbed/install/genirack/shared-vms.ns

  Expect the first swap-in to fail, since loading the disk for the first
  time will probably time out.  Try it again to make sure things do
  subsequently come up properly.

* Need to reset the mailing lists to the local admin.

  All of the mailing lists are stored in ops:/etc/mail/lists. Add the local
  admin to the testbed-*.list files. Do not change the defs file, since we
  want the email to go to the local admin *and* Utah.

* Run register_resources

	boss> wap /usr/testbed/sbin/protogeni/register_resources

* At this point, contact the GPO infrastructure people to find out
  what port and what vlan number to use for the mesoscale vlan. The
  instructions below use port 24 and vlan 1750, but that MIGHT NOT BE
  THE CASE. 

  Once you you know, telnet to the 5400:

	5400> config
	5400(config)# openflow
	5400(openFlow)# vlan 1750
	5400(openFlow vlan-1750)# enable
	5400(openFlow vlan-1750)# controller "tcp:10.3.1.7:6633" fail-secure on
	5400(openFlow vlan-1750)# exit
	5400(openFlow)# exit
	5400(config)> write memory

  Then on boss:

	boss> wap addspecialdevice -t interconnect -s 100 interconnect-geni-core
        boss> wap addspecialiface -b 1Gb -s procurve2,1,24 interconnect-geni-core eth0

  Now create and share the openflow vlan:

	boss> wap snmpit --vlan_tag=1750 -m mesoscale-openflow \
		emulab-ops openflow-vlans interconnect-geni-core:eth0
	boss> wap sharevlan -f -o emulab-ops,openflow-vlans \
		mesoscale-openflow mesoscale-openflow

* Send email to local admin with pointer to instructions on getting their
  admin account on boss: http://www.protogeni.net/wiki/RackAdminAccounts

---
TODO:

routable ip space when baking the images.
Enable necessary features.

-----
