--- linux-2.4.20-31.9/Documentation/Configure.help	2004-04-13 15:07:19.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/Documentation/Configure.help	2004-08-21 19:28:49.000000000 -0600
@@ -2835,6 +2835,14 @@
   If you want to compile it as a module, say M here and read
   <file:Documentation/modules.txt>.  If unsure, say `N'.
 
+IMQ target support
+CONFIG_IP_NF_TARGET_IMQ
+  This option adds a `IMQ' target which is used to specify if and
+  to which imq device packets should get enqueued/dequeued.
+
+  If you want to compile it as a module, say M here and read
+  <file:Documentation/modules.txt>.  If unsure, say `N'.
+
 MARK target support
 CONFIG_IP_NF_TARGET_MARK
   This option adds a `MARK' target, which allows you to create rules
@@ -3018,6 +3026,14 @@
   If you want to compile it as a module, say M here and read
   <file:Documentation/modules.txt>.  If unsure, say `N'.
 
+IMQ target support
+CONFIG_IP6_NF_TARGET_IMQ
+  This option adds a `IMQ' target which is used to specify if and
+  to which imq device packets should get enqueued/dequeued.
+
+  If you want to compile it as a module, say M here and read
+  <file:Documentation/modules.txt>.  If unsure, say `N'.
+
 MARK target support
 CONFIG_IP6_NF_TARGET_MARK
   This option adds a `MARK' target, which allows you to create rules
@@ -8826,6 +8842,20 @@
   say M here and read <file:Documentation/modules.txt>.  The module
   will be called bonding.o.
 
+Intermediate queueing device support
+CONFIG_IMQ
+  The imq device(s) is used as placeholder for QoS queueing disciplines.
+  Every packet entering/leaving the ip stack can be directed through
+  the imq device where it's enqueued/dequeued to the attached qdisc.
+  This allows you to treat network devices as classes and distribute
+  bandwidth among them. Iptables is used to specify through which imq
+  device, if any, packets travel.
+
+  If you want to compile this as a module ( = code which ca be
+  inserted in and removed from the running kernel whenever you want),
+  say M here and read <file:Documentation/modules.txt>.  The module
+  will be called imq.o
+
 SLIP (serial line) support
 CONFIG_SLIP
   Say Y if you intend to use SLIP or CSLIP (compressed SLIP) to
@@ -9856,6 +9886,32 @@
   The available schedulers are listed in the following questions; you
   can say Y to as many as you like. If unsure, say N now.
 
+PLR packet scheduler
+CONFIG_NET_SCH_PLR
+  Provides the facility to drop packets on a given interface 
+  at a specified packet loss rate (percentage 0-100). In general,
+  there's no need for this option unless you want to perform
+  network testing with artificially produced packet loss.
+  
+  If you say Y or M now, your networking will not be affected 
+  unless you enable the packet scheduler via the iproute2+tc 
+  package.
+  
+  If unsure, say N now.
+
+Delay packet scheduler
+CONFIG_NET_SCH_DELAY
+  Provides the facility to delay the delivery of IP packets on
+  a given interface for a specified number of usecs. In general,
+  there's no need for this option unless you want to perform
+  network testing with artificially produced latencies.
+  
+  If you say Y or M now, your networking will not be affected 
+  unless you enable the packet scheduler via the iproute2+tc 
+  package.
+  
+  If unsure, say N now.
+
 CBQ packet scheduler
 CONFIG_NET_SCH_CBQ
   Say Y here if you want to use the Class-Based Queueing (CBQ) packet

--- linux-2.4.20-31.9/drivers/net/Config.in	2004-04-13 15:07:13.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/drivers/net/Config.in	2004-08-21 19:28:49.000000000 -0600
@@ -7,6 +7,11 @@
 tristate 'Dummy net driver support' CONFIG_DUMMY
 tristate 'Bonding driver support' CONFIG_BONDING
 tristate 'EQL (serial line load balancing) support' CONFIG_EQUALIZER
+if [ "$CONFIG_NETFILTER" = "y" ]; then
+  tristate 'IMQ (intermediate queueing device) support' CONFIG_IMQ
+else
+  comment 'IMQ needs CONFIG_NETFILTER enabled'
+fi
 tristate 'Universal TUN/TAP device driver support' CONFIG_TUN
 if [ "$CONFIG_EXPERIMENTAL" = "y" ]; then
    tristate 'Ethertap network tap (OBSOLETE)' CONFIG_ETHERTAP

--- linux-2.4.20-31.9/drivers/net/Makefile	2004-04-13 15:07:16.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/drivers/net/Makefile	2004-08-21 19:28:49.000000000 -0600
@@ -159,6 +159,7 @@
 obj-$(CONFIG_STRIP) += strip.o
 obj-$(CONFIG_DUMMY) += dummy.o
 obj-$(CONFIG_BONDING) += bonding.o
+obj-$(CONFIG_IMQ) += imq.o
 obj-$(CONFIG_DE600) += de600.o
 obj-$(CONFIG_DE620) += de620.o
 obj-$(CONFIG_AT1500) += lance.o

--- linux-2.4.20-31.9/drivers/net/imq.c	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/drivers/net/imq.c	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,324 @@
+/*
+ *             Pseudo-driver for the intermediate queue device.
+ *
+ * Authors:    Patrick McHardy, <kaber@trash.net>
+ *
+ * 	       The first version was written by Martin Devera, <devik@cdi.cz>
+ * 
+ *             This program is free software; you can redistribute it and/or
+ *             modify it under the terms of the GNU General Public License
+ *             as published by the Free Software Foundation; either version
+ *             2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/config.h>
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/if_arp.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#if defined(CONFIG_IPV6) || defined (CONFIG_IPV6_MODULE)
+#include <linux/netfilter_ipv6.h>
+#endif
+#include <linux/imq.h>
+#include <net/pkt_sched.h>
+
+#define IMQ_HH_LEN(info)	(((info)->hook == NF_IP_PRE_ROUTING) ?    \
+					(info)->indev->hard_header_len :  \
+					(info)->outdev->hard_header_len)
+	
+static nf_hookfn imq_nf_hook;
+
+static struct nf_hook_ops imq_ingress_ipv4 = {
+	{ NULL, NULL},
+	imq_nf_hook,
+	PF_INET,
+	NF_IP_PRE_ROUTING,
+	NF_IP_PRI_MANGLE + 1
+};
+
+static struct nf_hook_ops imq_egress_ipv4 = {
+	{ NULL, NULL},
+	imq_nf_hook,
+	PF_INET,
+	NF_IP_POST_ROUTING,
+	NF_IP_PRI_LAST
+};
+
+#if defined(CONFIG_IPV6) || defined (CONFIG_IPV6_MODULE)
+static struct nf_hook_ops imq_ingress_ipv6 = {
+	{ NULL, NULL},
+	imq_nf_hook,
+	PF_INET6,
+	NF_IP6_PRE_ROUTING,
+	NF_IP6_PRI_MANGLE + 1
+};
+
+static struct nf_hook_ops imq_egress_ipv6 = {
+	{ NULL, NULL},
+	imq_nf_hook,
+	PF_INET6,
+	NF_IP6_POST_ROUTING,
+	NF_IP6_PRI_LAST
+};
+#endif
+
+static unsigned int numdevs = 2;
+
+MODULE_PARM(numdevs, "i");
+MODULE_PARM_DESC(numdevs, "number of imq devices");
+
+static struct net_device *imq_devs;
+
+
+static struct net_device_stats *imq_get_stats(struct net_device *dev)
+{
+	return (struct net_device_stats *)dev->priv;
+}
+
+/* called for packets kfree'd in qdiscs at places other than enqueue */
+static void imq_skb_destructor(struct sk_buff *skb)
+{
+	struct nf_info *info = skb->nf_info;
+
+	if (info) {
+		if (info->indev)
+			dev_put(info->indev);
+		if (info->outdev)
+			dev_put(info->outdev);
+		kfree(info);
+	}
+}
+
+static int imq_dev_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct net_device_stats *stats = (struct net_device_stats*) dev->priv;
+	
+	stats->tx_bytes += skb->len;
+	stats->tx_packets++;
+
+	skb_pull(skb, IMQ_HH_LEN(skb->nf_info));
+
+	skb->imq_flags = 0;
+	skb->destructor = NULL;
+	
+	dev->trans_start = jiffies;
+	nf_reinject(skb, skb->nf_info, NF_ACCEPT);
+
+	return 0;
+}
+
+static int imq_nf_queue(struct sk_buff *skb, struct nf_info *info,
+			void *data)
+{
+	struct net_device *dev;
+	struct net_device_stats *stats;
+	struct sk_buff *skb2 = NULL;
+	struct Qdisc *q;
+	unsigned int index = skb->imq_flags&IMQ_F_IFMASK;
+	int ret = -1;
+
+	if (index > numdevs) 
+		return -1;
+	
+	dev = imq_devs + index;
+	if (!(dev->flags & IFF_UP)) {
+		skb->imq_flags = 0;
+		nf_reinject(skb, info, NF_ACCEPT);
+		return 0;
+	}
+	dev->last_rx = jiffies;
+
+	if (skb->destructor) {
+		skb2 = skb;
+		skb = skb_clone(skb, GFP_ATOMIC);
+		if (!skb)
+			return -1;
+	}
+	skb_push(skb, IMQ_HH_LEN(info));
+	skb->nf_info = info;
+
+	stats = (struct net_device_stats *)dev->priv;
+	stats->rx_bytes+= skb->len;
+	stats->rx_packets++;
+	
+	spin_lock_bh(&dev->queue_lock);
+	
+	q = dev->qdisc;
+	if (q->enqueue) {
+		q->enqueue(skb_get(skb), q);
+
+		if (skb_shared(skb)) {
+			skb->destructor = imq_skb_destructor;
+			kfree_skb(skb);
+			ret = 0;
+		}
+	}
+
+	qdisc_run(dev);
+	spin_unlock_bh(&dev->queue_lock);
+
+	if (skb2)
+		kfree_skb(ret ? skb : skb2);
+
+	return ret;
+}
+
+static unsigned int imq_nf_hook(unsigned int hook, struct sk_buff **pskb,
+		   const struct net_device *indev,
+		   const struct net_device *outdev,
+		   int (*okfn)(struct sk_buff *))
+{
+	if ((*pskb)->imq_flags & IMQ_F_ENQUEUE)
+		return NF_QUEUE;
+
+	return NF_ACCEPT;
+}
+
+
+static int __init imq_init_hooks(void)
+{
+	int err;
+
+	if ((err = nf_register_queue_handler(PF_INET, imq_nf_queue, NULL)))
+		goto err1;
+	if ((err = nf_register_hook(&imq_ingress_ipv4)))
+		goto err2;
+	if ((err = nf_register_hook(&imq_egress_ipv4)))
+		goto err3;
+#if defined(CONFIG_IPV6) || defined (CONFIG_IPV6_MODULE)
+	if ((err = nf_register_queue_handler(PF_INET6, imq_nf_queue, NULL)))
+		goto err4;
+	if ((err = nf_register_hook(&imq_ingress_ipv6)))
+		goto err5;
+	if ((err = nf_register_hook(&imq_egress_ipv6)))
+		goto err6;
+#endif
+	
+	return 0;
+	
+#if defined(CONFIG_IPV6) || defined (CONFIG_IPV6_MODULE)
+err6:
+	nf_unregister_hook(&imq_ingress_ipv6);
+err5:
+	nf_unregister_queue_handler(PF_INET6);
+err4:
+	nf_unregister_hook(&imq_egress_ipv4);
+#endif
+err3:
+	nf_unregister_hook(&imq_ingress_ipv4);
+err2:
+	nf_unregister_queue_handler(PF_INET);
+err1:
+	return err;
+}
+
+static void __exit imq_unhook(void)
+{
+	nf_unregister_hook(&imq_ingress_ipv4);
+	nf_unregister_hook(&imq_egress_ipv4);
+	nf_unregister_queue_handler(PF_INET);
+#if defined(CONFIG_IPV6) || defined (CONFIG_IPV6_MODULE)
+	nf_unregister_hook(&imq_ingress_ipv6);
+	nf_unregister_hook(&imq_egress_ipv6);
+	nf_unregister_queue_handler(PF_INET6);
+#endif
+}
+
+static int __init imq_dev_init(struct net_device *dev)
+{
+	dev->hard_start_xmit	= imq_dev_xmit;
+	dev->type		= ARPHRD_VOID;
+	dev->mtu		= 1500;
+	dev->tx_queue_len	= 30;
+	dev->flags		= IFF_NOARP;
+	dev->priv = kmalloc(sizeof(struct net_device_stats), GFP_KERNEL);
+	if (dev->priv == NULL)
+		return -ENOMEM;
+	memset(dev->priv, 0, sizeof(struct net_device_stats));
+	dev->get_stats		= imq_get_stats;
+
+	return 0;
+}
+
+static void imq_dev_uninit(struct net_device *dev)
+{
+	kfree(dev->priv);
+}
+
+static int __init imq_init_devs(void)
+{
+	struct net_device *dev;
+	int i;
+
+	if (!numdevs || numdevs > IMQ_MAX_DEVS) {
+		printk(KERN_ERR "numdevs has to be betweed 1 and %u\n",
+		       IMQ_MAX_DEVS);
+		return -EINVAL;
+	}
+
+	imq_devs = kmalloc(sizeof(struct net_device) * numdevs, GFP_KERNEL);
+	if (!imq_devs)
+		return -ENOMEM;
+	memset(imq_devs, 0, sizeof(struct net_device) * numdevs);
+
+	/* we start counting at zero */
+	numdevs--;
+
+	for (i = 0, dev = imq_devs; i <= numdevs; i++, dev++) {
+		SET_MODULE_OWNER(dev);
+		strcpy(dev->name, "imq%d");
+		dev->init   = imq_dev_init;
+		dev->uninit = imq_dev_uninit;
+
+		if (register_netdev(dev) < 0)
+			goto err_register;
+	}
+	return 0;
+
+err_register:
+	for (; i; i--)
+		unregister_netdev(--dev);
+	kfree(imq_devs);
+	return -EIO;
+}
+
+static void imq_cleanup_devs(void)
+{
+	int i;
+	struct net_device *dev = imq_devs;
+	
+	for (i = 0; i <= numdevs; i++)
+		unregister_netdev(dev++);
+
+	kfree(imq_devs);
+}
+
+static int __init imq_init_module(void)
+{
+	int err;
+
+	if ((err = imq_init_devs()))
+		return err;
+	if ((err = imq_init_hooks())) {
+		imq_cleanup_devs();
+		return err;
+	}
+
+	printk(KERN_INFO "imq driver loaded.\n");
+
+	return 0;
+}
+
+static void __exit imq_cleanup_module(void)
+{
+	imq_unhook();
+	imq_cleanup_devs();
+}
+
+module_init(imq_init_module);
+module_exit(imq_cleanup_module);
+MODULE_LICENSE("GPL");

--- linux-2.4.20-31.9/include/linux/imq.h	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/include/linux/imq.h	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,9 @@
+#ifndef _IMQ_H
+#define _IMQ_H
+
+#define IMQ_MAX_DEVS	16
+
+#define IMQ_F_IFMASK	0x7f
+#define IMQ_F_ENQUEUE	0x80
+
+#endif /* _IMQ_H */

--- linux-2.4.20-31.9/include/linux/netfilter_ipv4/ipt_IMQ.h	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/include/linux/netfilter_ipv4/ipt_IMQ.h	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,8 @@
+#ifndef _IPT_IMQ_H
+#define _IPT_IMQ_H
+
+struct ipt_imq_info {
+	unsigned int todev;	/* target imq device */
+};
+
+#endif /* _IPT_IMQ_H */

--- linux-2.4.20-31.9/include/linux/netfilter_ipv6/ip6t_IMQ.h	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/include/linux/netfilter_ipv6/ip6t_IMQ.h	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,8 @@
+#ifndef _IP6T_IMQ_H
+#define _IP6T_IMQ_H
+
+struct ip6t_imq_info {
+	unsigned int todev;	/* target imq device */
+};
+
+#endif /* _IP6T_IMQ_H */

--- linux-2.4.20-31.9/include/linux/pkt_sched.h	2002-11-28 16:53:15.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/include/linux/pkt_sched.h	2004-08-21 19:28:49.000000000 -0600
@@ -93,6 +93,21 @@
 	__u32	limit;	/* Queue length: bytes for bfifo, packets for pfifo */
 };
 
+/* PLR section */
+
+struct tc_plr_qopt
+{
+	__u32 plr; /* % drop rate (0-100) */
+};
+
+/* DELAY section */
+
+struct tc_delay_qopt
+{
+	__u32 delay_usec; /* # of usecs to delay */
+  __u8  reset_time;       /* flag: reset time on dequeue, or not */
+};
+
 /* PRIO section */
 
 #define TCQ_PRIO_BANDS	16

--- linux-2.4.20-31.9/include/linux/skbuff.h	2004-04-13 15:41:43.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/include/linux/skbuff.h	2004-08-21 19:28:49.000000000 -0600
@@ -93,6 +93,9 @@
 	struct nf_conntrack *master;
 };
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+struct nf_info;
+#endif
 
 struct sk_buff_head {
 	/* These two members must be first. */
@@ -178,7 +181,7 @@
 	unsigned int 	len;			/* Length of actual data			*/
  	unsigned int 	data_len;
 	unsigned int	csum;			/* Checksum 					*/
-	unsigned char 	__unused,		/* Dead field, may be reused			*/
+	unsigned char 	imq_flags,		/* intermediate queueing device	*/
 			cloned, 		/* head may be cloned (check refcnt to be sure). */
   			pkt_type,		/* Packet class					*/
   			ip_summed;		/* Driver fed us an IP checksum			*/
@@ -215,6 +218,9 @@
 #ifdef CONFIG_NET_SCHED
        __u32           tc_index;               /* traffic control index */
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+       struct nf_info	*nf_info;
+#endif
 };
 
 #define SK_WMEM_MAX	65535

--- linux-2.4.20-31.9/include/net/pkt_sched.h	2004-04-13 15:41:44.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/include/net/pkt_sched.h	2004-08-21 19:28:49.000000000 -0600
@@ -5,7 +5,8 @@
 #define PSCHED_JIFFIES 		2
 #define PSCHED_CPU 		3
 
-#define PSCHED_CLOCK_SOURCE	PSCHED_JIFFIES
+/* #define PSCHED_CLOCK_SOURCE	PSCHED_JIFFIES */
+#define PSCHED_CLOCK_SOURCE	PSCHED_GETTIMEOFDAY
 
 #include <linux/config.h>
 #include <linux/types.h>

--- linux-2.4.20-31.9/net/core/skbuff.c	2004-04-13 15:07:11.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/net/core/skbuff.c	2004-08-21 19:28:49.000000000 -0600
@@ -202,6 +202,10 @@
 	/* Set up other state */
 	skb->len = 0;
 	skb->cloned = 0;
+#if defined(CONFIG_IMQ) || defined (CONFIG_IMQ_MODULE)
+	skb->imq_flags = 0;
+	skb->nf_info = NULL;
+#endif
 	skb->data_len = 0;
 
 	atomic_set(&skb->users, 1); 
@@ -249,6 +253,10 @@
 #ifdef CONFIG_NET_SCHED
 	skb->tc_index = 0;
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	skb->imq_flags = 0;
+	skb->nf_info = NULL;
+#endif
 }
 
 static void skb_drop_fraglist(struct sk_buff *skb)
@@ -398,6 +406,10 @@
 #ifdef CONFIG_NET_SCHED
 	C(tc_index);
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	C(imq_flags);
+	C(nf_info);
+#endif
 
 	atomic_inc(&(skb_shinfo(skb)->dataref));
 	skb->cloned = 1;
@@ -441,6 +453,10 @@
 #ifdef CONFIG_NET_SCHED
 	new->tc_index = old->tc_index;
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	new->imq_flags=old->imq_flags;
+	new->nf_info=old->nf_info;
+#endif
 }
 
 /**

--- linux-2.4.20-31.9/net/ipv4/netfilter/Config.in	2004-04-13 15:07:12.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/net/ipv4/netfilter/Config.in	2004-08-21 19:28:49.000000000 -0600
@@ -103,6 +103,7 @@
     dep_tristate '    DSCP target support' CONFIG_IP_NF_TARGET_DSCP $CONFIG_IP_NF_MANGLE
  
     dep_tristate '    MARK target support' CONFIG_IP_NF_TARGET_MARK $CONFIG_IP_NF_MANGLE
+    dep_tristate '    IMQ target support' CONFIG_IP_NF_TARGET_IMQ $CONFIG_IP_NF_MANGLE
   fi
   dep_tristate '  LOG target support' CONFIG_IP_NF_TARGET_LOG $CONFIG_IP_NF_IPTABLES
   dep_tristate '  ULOG target support' CONFIG_IP_NF_TARGET_ULOG $CONFIG_IP_NF_IPTABLES

--- linux-2.4.20-31.9/net/ipv4/netfilter/Makefile	2004-04-13 15:07:12.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/net/ipv4/netfilter/Makefile	2004-08-21 19:28:49.000000000 -0600
@@ -93,6 +93,7 @@
 obj-$(CONFIG_IP_NF_TARGET_ECN) += ipt_ECN.o
 obj-$(CONFIG_IP_NF_TARGET_DSCP) += ipt_DSCP.o
 obj-$(CONFIG_IP_NF_TARGET_MARK) += ipt_MARK.o
+obj-$(CONFIG_IP_NF_TARGET_IMQ) += ipt_IMQ.o
 obj-$(CONFIG_IP_NF_TARGET_MASQUERADE) += ipt_MASQUERADE.o
 obj-$(CONFIG_IP_NF_TARGET_REDIRECT) += ipt_REDIRECT.o
 obj-$(CONFIG_IP_NF_NAT_SNMP_BASIC) += ip_nat_snmp_basic.o

--- linux-2.4.20-31.9/net/ipv4/netfilter/ipt_IMQ.c	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/ipv4/netfilter/ipt_IMQ.c	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,78 @@
+/* This target marks packets to be enqueued to an imq device */
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/netfilter_ipv4/ipt_IMQ.h>
+#include <linux/imq.h>
+
+static unsigned int imq_target(struct sk_buff **pskb,
+			       unsigned int hooknum,
+			       const struct net_device *in,
+			       const struct net_device *out,
+			       const void *targinfo,
+			       void *userinfo)
+{
+	struct ipt_imq_info *mr = (struct ipt_imq_info*)targinfo;
+
+	(*pskb)->imq_flags = mr->todev | IMQ_F_ENQUEUE;
+	(*pskb)->nfcache |= NFC_ALTERED;
+
+	return IPT_CONTINUE;
+}
+
+static int imq_checkentry(const char *tablename,
+			  const struct ipt_entry *e,
+			  void *targinfo,
+			  unsigned int targinfosize,
+			  unsigned int hook_mask)
+{
+	struct ipt_imq_info *mr;
+
+	if (targinfosize != IPT_ALIGN(sizeof(struct ipt_imq_info))) {
+		printk(KERN_WARNING "IMQ: invalid targinfosize\n");
+		return 0;
+	}
+	mr = (struct ipt_imq_info*)targinfo;
+
+	if (strcmp(tablename, "mangle") != 0) {
+		printk(KERN_WARNING
+		       "IMQ: IMQ can only be called from \"mangle\" table, not \"%s\"\n",
+		       tablename);
+		return 0;
+	}
+	
+	if (mr->todev > IMQ_MAX_DEVS) {
+		printk(KERN_WARNING
+		       "IMQ: invalid device specified, highest is %u\n",
+		       IMQ_MAX_DEVS);
+		return 0;
+	}
+	
+	return 1;
+}
+
+static struct ipt_target ipt_imq_reg = {
+	{ NULL, NULL},
+	"IMQ",
+	imq_target,
+	imq_checkentry,
+	NULL,
+	THIS_MODULE
+};
+
+static int __init init(void)
+{
+	if (ipt_register_target(&ipt_imq_reg))
+		return -EINVAL;
+
+	return 0;
+}
+
+static void __exit fini(void)
+{
+	ipt_unregister_target(&ipt_imq_reg);
+}
+
+module_init(init);
+module_exit(fini);
+MODULE_LICENSE("GPL");

--- linux-2.4.20-31.9/net/ipv6/netfilter/Config.in	2004-04-13 15:07:12.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/net/ipv6/netfilter/Config.in	2004-08-21 19:28:49.000000000 -0600
@@ -71,6 +71,7 @@
   if [ "$CONFIG_IP6_NF_MANGLE" != "n" ]; then
 #    dep_tristate '    TOS target support' CONFIG_IP6_NF_TARGET_TOS $CONFIG_IP_NF_MANGLE
     dep_tristate '    MARK target support' CONFIG_IP6_NF_TARGET_MARK $CONFIG_IP6_NF_MANGLE
+    dep_tristate '    IMQ target support' CONFIG_IP6_NF_TARGET_IMQ $CONFIG_IP6_NF_MANGLE
   fi
   #dep_tristate '  LOG target support' CONFIG_IP6_NF_TARGET_LOG $CONFIG_IP6_NF_IPTABLES
 fi

--- linux-2.4.20-31.9/net/ipv6/netfilter/Makefile	2004-04-13 15:07:12.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/net/ipv6/netfilter/Makefile	2004-08-21 19:28:49.000000000 -0600
@@ -28,6 +28,7 @@
 obj-$(CONFIG_IP6_NF_FILTER) += ip6table_filter.o
 obj-$(CONFIG_IP6_NF_MANGLE) += ip6table_mangle.o
 obj-$(CONFIG_IP6_NF_TARGET_MARK) += ip6t_MARK.o
+obj-$(CONFIG_IP6_NF_TARGET_IMQ) += ip6t_IMQ.o
 obj-$(CONFIG_IP6_NF_QUEUE) += ip6_queue.o
 obj-$(CONFIG_IP6_NF_TARGET_LOG) += ip6t_LOG.o
 obj-$(CONFIG_IP6_NF_MATCH_HL) += ip6t_hl.o

--- linux-2.4.20-31.9/net/ipv6/netfilter/ip6t_IMQ.c	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/ipv6/netfilter/ip6t_IMQ.c	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,78 @@
+/* This target marks packets to be enqueued to an imq device */
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter_ipv6/ip6_tables.h>
+#include <linux/netfilter_ipv6/ip6t_IMQ.h>
+#include <linux/imq.h>
+
+static unsigned int imq_target(struct sk_buff **pskb,
+			       unsigned int hooknum,
+			       const struct net_device *in,
+			       const struct net_device *out,
+			       const void *targinfo,
+			       void *userinfo)
+{
+	struct ip6t_imq_info *mr = (struct ip6t_imq_info*)targinfo;
+
+	(*pskb)->imq_flags = mr->todev | IMQ_F_ENQUEUE;
+	(*pskb)->nfcache |= NFC_ALTERED;
+
+	return IP6T_CONTINUE;
+}
+
+static int imq_checkentry(const char *tablename,
+			  const struct ip6t_entry *e,
+			  void *targinfo,
+			  unsigned int targinfosize,
+			  unsigned int hook_mask)
+{
+	struct ip6t_imq_info *mr;
+
+	if (targinfosize != IP6T_ALIGN(sizeof(struct ip6t_imq_info))) {
+		printk(KERN_WARNING "IMQ: invalid targinfosize\n");
+		return 0;
+	}
+	mr = (struct ip6t_imq_info*)targinfo;
+
+	if (strcmp(tablename, "mangle") != 0) {
+		printk(KERN_WARNING
+		       "IMQ: IMQ can only be called from \"mangle\" table, not \"%s\"\n",
+		       tablename);
+		return 0;
+	}
+	
+	if (mr->todev > IMQ_MAX_DEVS) {
+		printk(KERN_WARNING
+		       "IMQ: invalid device specified, highest is %u\n",
+		       IMQ_MAX_DEVS);
+		return 0;
+	}
+	
+	return 1;
+}
+
+static struct ip6t_target ip6t_imq_reg = {
+	{ NULL, NULL},
+	"IMQ",
+	imq_target,
+	imq_checkentry,
+	NULL,
+	THIS_MODULE
+};
+
+static int __init init(void)
+{
+	if (ip6t_register_target(&ip6t_imq_reg))
+		return -EINVAL;
+
+	return 0;
+}
+
+static void __exit fini(void)
+{
+	ip6t_unregister_target(&ip6t_imq_reg);
+}
+
+module_init(init);
+module_exit(fini);
+MODULE_LICENSE("GPL");

--- linux-2.4.20-31.9/net/sched/Config.in	2002-11-28 16:53:16.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/sched/Config.in	2004-08-21 19:28:49.000000000 -0600
@@ -1,6 +1,8 @@
 #
 # Traffic control configuration.
 # 
+tristate '  DELAY packet scheduler' CONFIG_NET_SCH_DELAY
+tristate '  PLR packet scheduler' CONFIG_NET_SCH_PLR
 tristate '  CBQ packet scheduler' CONFIG_NET_SCH_CBQ
 tristate '  HTB packet scheduler' CONFIG_NET_SCH_HTB
 tristate '  CSZ packet scheduler' CONFIG_NET_SCH_CSZ

--- linux-2.4.20-31.9/net/sched/Makefile	2002-11-28 16:53:16.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/sched/Makefile	2004-08-21 19:28:49.000000000 -0600
@@ -12,6 +12,8 @@
 obj-$(CONFIG_NET_CLS)		+= cls_api.o
 obj-$(CONFIG_NET_CLS_POLICE)	+= police.o
 obj-$(CONFIG_NET_SCH_INGRESS)	+= sch_ingress.o 
+obj-$(CONFIG_NET_SCH_DELAY)	+= sch_delay.o
+obj-$(CONFIG_NET_SCH_PLR)	+= sch_plr.o
 obj-$(CONFIG_NET_SCH_CBQ)	+= sch_cbq.o
 obj-$(CONFIG_NET_SCH_CSZ)	+= sch_csz.o
 obj-$(CONFIG_NET_SCH_HPFQ)	+= sch_hpfq.o

--- linux-2.4.20-31.9/net/sched/sch_api.c	2002-11-28 16:53:16.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/sched/sch_api.c	2004-08-21 19:28:49.000000000 -0600
@@ -1232,6 +1232,12 @@
 #ifdef CONFIG_NET_SCH_SFQ
 	INIT_QDISC(sfq);
 #endif
+#ifdef CONFIG_NET_SCH_PLR
+	INIT_QDISC(plr);
+#endif
+#ifdef CONFIG_NET_SCH_DELAY
+	INIT_QDISC(delay);
+#endif
 #ifdef CONFIG_NET_SCH_TBF
 	INIT_QDISC(tbf);
 #endif

--- linux-2.4.20-31.9/net/sched/sch_delay.c	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/sched/sch_delay.c	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,738 @@
+/*
+ * net/sched/sch_delay.c	Add a delay to anything going out...
+ *
+ *		This program is free software; you can redistribute it and/or
+ *		modify it under the terms of the GNU General Public License
+ *		as published by the Free Software Foundation; either version
+ *		2 of the License, or (at your option) any later version.
+ *
+ * Authors:	
+ *         David T McWherter, <dtm@vramp.net>
+ *         Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/bitops.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/string.h>
+#include <linux/mm.h>
+#include <linux/socket.h>
+#include <linux/sockios.h>
+#include <linux/in.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/if_ether.h>
+#include <linux/inet.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/notifier.h>
+#include <net/ip.h>
+#include <net/route.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <net/pkt_sched.h>
+
+/*  Delay Scheduler
+    =======================================
+	Provides the facility to delay the delivery of IP packets on
+	a given interface for a specified number of usecs. In general,
+	there's no need for this option unless you want to perform 
+	network testing with artificially produced latencies.
+ */
+
+#define DQDISC (1<<16)
+#define DCLASS (1<<17)
+#define DSTATS (1<<18)
+
+/* debugging level & bitmask: upper 16 bits are debug mask, lower 16
+   are level */
+/* bits for mask are defined above, and level is 0 - 1000 */
+#define DBG DSTATS | 1000
+
+#if 0
+#define DMSK(lvl) ((lvl) & 0xffff0000)
+#define DLVL(lvl)  ((lvl) & 0x0000ffff)
+#define DPRINTK(lvl, fmt, args...)   if ((DMSK(lvl) & DMSK(DBG)) && \
+                                         (DLVL(lvl) < DLVL(DBG))) \
+                                       { printk(KERN_DEBUG fmt, ##args); }
+#else
+#define DMSK(lvl)
+#define DLVL(lvl)
+#define DPRINTK(lvl, fmt, args...)
+#endif
+
+#define EPRINTK(fmt, args...)    printk(KERN_ERR fmt, ##args);
+
+#define TN_MAGIC 94343939L
+
+/* delay packet queue lock */
+static rwlock_t delay_mod_lock = RW_LOCK_UNLOCKED;
+
+/* XXX: temp for debugging */
+static __u32 oldbklog;
+
+struct time_node {
+  struct list_head      link;
+  long                  magic;
+  psched_time_t	        time;
+};
+
+#define LIST_ENTRY(x)           list_entry((x), struct time_node, link)
+
+struct delay_sched_data
+{
+  struct Qdisc      *qd;         /* Child qdisc pointer */
+  struct tcf_proto  *filter_list; /* tc filter chain - unused. */
+  struct time_node  times_queue; /* The queue of socket input times */
+  struct timer_list wd_timer;    /* watchdog timer */
+  psched_tdiff_t    delaytime;   /* The amount of time to delay sending packets */
+  __u8              reset_time;  /* Should sk_buff time get reset?: flag */
+};
+
+
+/**
+ * time_node utility functions.
+ */
+static struct time_node *
+time_node_alloc (void)
+{
+  struct time_node * out;
+  DPRINTK(DQDISC | 50, "{ time_node_alloc\n");
+  out = (struct time_node*)kmalloc( sizeof(struct time_node), GFP_ATOMIC );
+  if ( !out )
+    {
+      EPRINTK("!!! - NULL time_node_alloc\n");
+    } else {
+      out->magic = TN_MAGIC;
+    }
+  DPRINTK(DQDISC | 50, "} time_node_alloc\n");
+  return out;
+}
+
+
+static void
+time_node_free( struct time_node * nd )
+{
+  if ( nd )
+    {
+      if ( nd->magic != TN_MAGIC )
+	{
+	  EPRINTK("!!! - time_node_free of %p with bad magic! (%ld)\n", 
+                       nd, (long)nd->magic);
+	} else { 
+          kfree(nd);
+	}
+    }
+}
+
+
+static struct time_node *
+time_node_stamp ( struct time_node * nd )
+{
+  if ( nd ) 
+    PSCHED_GET_TIME( nd->time );
+  return nd;
+}
+
+
+static struct time_node *
+time_node_queue_enqueue_head ( struct time_node * head, struct time_node * nd )
+{
+  if ( head && nd )
+    {
+      list_add(&nd->link, &head->link);
+    }
+  return nd;
+}
+
+
+static struct time_node *
+time_node_queue_enqueue_tail ( struct time_node * head, struct time_node * nd )
+{
+  DPRINTK(DQDISC | 50, "{ time_node_queue_enqueue_tail\n");
+  if ( head && nd )
+    {
+      list_add_tail(&nd->link, &head->link);
+    }
+  DPRINTK(DQDISC | 50, "} time_node_queue_enqueue_tail\n");
+  return nd;
+}
+
+
+static struct time_node * 
+time_node_queue_dequeue_head ( struct time_node * head )
+{
+  struct time_node * first = NULL;
+  DPRINTK(DQDISC | 50, "{ time_node_queue_dequeue_head\n");
+  if ( head )
+    {
+      if ( !list_empty(&head->link) )
+	{
+          first = LIST_ENTRY(head->link.next);
+          list_del(head->link.next);
+	}
+    }
+  DPRINTK(DQDISC | 50, "} time_node_queue_dequeue_head\n");
+  return first;
+}
+
+
+static struct time_node * 
+time_node_queue_peek_head ( struct time_node * head )
+{
+  struct time_node * first = NULL;
+  DPRINTK(DQDISC | 50, "{ time_node_queue_peek_head\n");
+  if ( head )
+    {
+      if ( !list_empty(&head->link) )
+	{
+          first = LIST_ENTRY(head->link.next);
+	}
+    }
+  DPRINTK(DQDISC | 50, "} time_node_queue_peek_head\n");
+  return first;
+}
+
+
+static struct time_node * 
+time_node_queue_purge ( struct time_node * head )
+{
+  DPRINTK(DQDISC | 50, "{ time_node_queue_purge(%p)\n", head);
+  if ( head )
+    {
+      for ( ; !list_empty(&head->link) ; )
+	{
+	  struct time_node * nd;
+	  nd = time_node_queue_dequeue_head ( head );
+	  time_node_free( nd );
+	}
+    }
+  DPRINTK(DQDISC | 50, "} time_node_queue_purge\n");
+  return head;
+}
+
+/**
+ * Watchdog timer
+ */
+static void delay_watchdog ( unsigned long arg )
+{
+  struct Qdisc * sch = (struct Qdisc*)arg;
+  psched_time_t foo;
+
+  PSCHED_GET_TIME(foo);
+  DPRINTK(DQDISC | 200, "Bang! WD fired at: %llu\n", foo);
+  netif_schedule( sch->dev );
+}
+
+/* ------------------------------------------------------------------------- */
+/* Class functions --------------------------------------------------------- */
+/* ------------------------------------------------------------------------- */
+
+static int 
+delay_graft(struct Qdisc *sch,unsigned long arg, 
+          struct Qdisc *new1,struct Qdisc **old)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+
+  DPRINTK(DCLASS | 100, "delay_graft(sch %p,[qdisc %p],new %p,old %p)\n",
+          sch,p,new1,old);
+  if (!new1)
+    new1 = &noop_qdisc;
+  sch_tree_lock(sch);
+  *old = xchg(&p->qd,new1);
+  if (*old)
+    qdisc_reset(*old);
+  sch_tree_unlock(sch); /* @@@ move up ? */
+  return 0;
+}
+
+
+static struct Qdisc*
+delay_leaf(struct Qdisc *sch, unsigned long arg)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+
+  return p->qd;
+}
+
+
+static unsigned long 
+delay_get(struct Qdisc *sch,u32 classid)
+{
+  struct delay_sched_data *p __attribute__((unused)) = 
+    (struct delay_sched_data *)sch->data;
+
+  DPRINTK(DCLASS | 100, "delay_get(sch %p,[qdisc %p],classid %x)\n",
+          sch,p,classid);
+  return 1; /* we currently only support one class so.. */
+}
+
+static int
+delay_class_change(struct Qdisc *sch, u32 classid, u32 parent,
+                 struct rtattr **tca, unsigned long *arg)
+{
+  return 0;
+}
+
+static unsigned long 
+delay_bind_filter(struct Qdisc *sch, unsigned long parent, u32 classid)
+{
+  return delay_get(sch,classid);
+}
+
+
+static void 
+delay_put(struct Qdisc *sch, unsigned long cl)
+{
+}
+
+static int 
+delay_delete(struct Qdisc *sch,unsigned long arg)
+{
+  struct delay_sched_data *p __attribute__((unused)) = 
+    (struct delay_sched_data *)sch->data;
+  
+  if (!arg)
+    return -EINVAL;
+  
+  return 0;
+}
+
+
+static void 
+delay_walk(struct Qdisc *sch,struct qdisc_walker *walker)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+  
+  DPRINTK(DCLASS | 100, "delay_walk(sch %p,[qdisc %p],walker %p)\n",
+          sch,p,walker);
+  
+  if (walker->stop)
+    return;
+  
+  if (walker->count >= walker->skip) {
+    if (walker->fn(sch, 1, walker) < 0) {
+      walker->stop = 1;
+    }
+  }
+  else {
+    walker->count++;
+  }
+}
+
+
+static struct tcf_proto**
+delay_find_tcf(struct Qdisc *sch,unsigned long cl)
+{
+	struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+
+	return &p->filter_list;
+}
+
+
+static int 
+delay_dump_class(struct Qdisc *sch, unsigned long cl, 
+               struct sk_buff *skb, struct tcmsg *tcm)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+  unsigned char *b = skb->tail;
+  
+  DPRINTK(DCLASS | 100, "delay_dump_class(sch %p,[qdisc %p],class %ld\n",
+          sch,p,cl);
+  tcm->tcm_handle = TC_H_MAKE(TC_H_MAJ(sch->handle),1);
+  RTA_PUT(skb,TCA_OPTIONS,0,NULL);
+
+  return skb->len;
+  
+ rtattr_failure:
+  skb_trim(skb,b-skb->data);
+  return -1;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/* Qdisc functions --------------------------------------------------------- */
+/* ------------------------------------------------------------------------- */
+
+static int
+delay_enqueue(struct sk_buff *skb, struct Qdisc* sch)
+{
+  struct delay_sched_data *q = (struct delay_sched_data *)sch->data;
+  int out = NET_XMIT_DROP;
+
+  DPRINTK(DQDISC, "{ delay_enqueue\n");
+
+  {
+    struct time_node * nd;
+    psched_time_t currtime;
+
+    PSCHED_GET_TIME(currtime);
+    DPRINTK(DQDISC | 200, "Enqueueing at: %llu\n", currtime);
+    nd = time_node_stamp(time_node_alloc());
+    if ( nd ) 
+      {
+        write_lock(&delay_mod_lock);
+	(void) time_node_queue_enqueue_tail( &q->times_queue, nd );
+	__skb_queue_tail(&sch->q, skb);
+        write_unlock(&delay_mod_lock);
+	sch->stats.backlog += skb->len;
+        if (sch->stats.backlog > oldbklog) {
+          oldbklog = sch->stats.backlog;
+          DPRINTK(DSTATS | 100, "Backlog increased to: %u\n", oldbklog);
+          DPRINTK(DSTATS | 100, "Queue size is: %u\n", sch->q.qlen);
+        }
+	sch->stats.bytes += skb->len;
+	sch->stats.packets++;
+        sch->q.qlen++;
+	out = 0; /* We don't drop packets - XXX: REVISE!*/
+      }
+  }
+
+  DPRINTK(DQDISC, "} delay_enqueue\n");
+
+  return out;
+}
+
+static int
+delay_requeue(struct sk_buff *skb, struct Qdisc* sch)
+{
+  int out = NET_XMIT_SUCCESS;
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+
+  DPRINTK(DQDISC, "{ delay_requeue\n");
+
+  /* We don't delay it a second time, just pass to inner queue. */
+  if ((out = p->qd->ops->requeue(skb, p->qd)) == 0) {
+    sch->q.qlen++;
+  }
+  else {
+    sch->stats.drops++;
+    out = NET_XMIT_DROP;
+  }
+
+  DPRINTK(DQDISC, "} delay_requeue\n");
+  return out;
+}
+
+static struct sk_buff *
+delay_dequeue(struct Qdisc* sch)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+  struct sk_buff *skb = 0;
+  struct time_node * nd;
+  psched_time_t currtime;
+  psched_time_t tmp;
+
+  DPRINTK(DQDISC, "{ delay_dequeue\n");
+
+  PSCHED_GET_TIME(currtime);
+
+  write_lock(&delay_mod_lock);
+  nd = time_node_queue_dequeue_head ( &p->times_queue );
+  if ( nd )
+    {
+      PSCHED_TADD2(nd->time, p->delaytime, tmp);
+
+      if (PSCHED_TLESS(tmp, currtime)) 
+	{
+          // dequeue the skb
+	  DPRINTK(DQDISC | 200, "time ((%llu+%ld)=%llu) < %llu, dequeuing\n",
+                  nd->time,p->delaytime,tmp,currtime);
+	  skb = __skb_dequeue( &sch->q );
+          /* XXX: should always be an sk_buff to accompany the time_node */
+	  if ( skb ) 
+	    {
+              if (p->reset_time) {
+                skb->stamp.tv_sec = currtime.tv_sec;
+                skb->stamp.tv_usec = currtime.tv_usec;
+              }
+	      sch->stats.backlog -= skb->len;
+              time_node_free(nd);
+	    }
+          if (p->qd->ops->enqueue(skb, p->qd) != 0) 
+            {
+              DPRINTK(DQDISC | DCLASS, "Child qdisc dropped delayed packet!\n");
+              sch->stats.drops++;
+              sch->q.qlen--;
+            }
+	} else {
+	  /* psched_time_t diff; */
+          
+	  DPRINTK(DQDISC | 200, "time ((%llu+%ld)=%llu) >= %llu, "
+                  "NOT dequeueing\n",
+                  nd->time,p->delaytime,tmp,currtime);
+          /* requeue the time */
+	  time_node_queue_enqueue_head ( &p->times_queue, nd );
+        }
+
+      /* update timer if any packets still exist in the queue */
+      nd = time_node_queue_peek_head( &p->times_queue );
+      if (nd && !netif_queue_stopped(sch->dev))
+        {
+          psched_tdiff_t diff;
+          
+          /* Calculate the wait time before we should be awakened */
+          PSCHED_TADD2(nd->time, p->delaytime, tmp);
+          diff = PSCHED_TDIFF(tmp, currtime);
+
+          if (diff < 1)
+            diff = 1;
+          
+          DPRINTK(DQDISC | 500, "Setting timer to expire at %lu jiffies.  "
+                  "Diff is %lu  Jiffies is %lu  HZ is %u\n", 
+                  jiffies + PSCHED_US2JIFFIE(diff),
+                  PSCHED_US2JIFFIE(diff),
+                  jiffies,
+                  HZ);
+          
+          mod_timer( &p->wd_timer, jiffies + PSCHED_US2JIFFIE(diff)); /* removed +100 */
+	}
+    }
+  write_unlock(&delay_mod_lock);
+  
+  skb = p->qd->ops->dequeue(p->qd);
+  if ( skb )
+    {
+      DPRINTK(DQDISC | 100, "delay_dequeue: really dequeueing packet\n");
+      sch->q.qlen--;
+    } 
+
+  DPRINTK(DQDISC, "} delay_dequeue\n");
+  return skb;
+}  
+
+
+static int
+delay_drop(struct Qdisc* sch)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+  struct sk_buff *skb;
+  int out = 0;
+
+  DPRINTK(DQDISC, "{ delay_drop\n");
+
+  write_lock(&delay_mod_lock);
+  skb = __skb_dequeue_tail(&sch->q);
+  if ( skb )
+    {
+      struct time_node * nd = 
+        time_node_queue_dequeue_head ( &p->times_queue );
+      time_node_free( nd );
+
+      sch->stats.backlog -= skb->len;
+      sch->stats.drops++;
+      sch->q.qlen--;
+      kfree_skb(skb);
+      out = 1; /* We succeeded */
+    }
+  else if (p->qd->ops->drop(p->qd)) 
+    {
+      sch->q.qlen--;
+      out = 1;
+    }
+  write_unlock(&delay_mod_lock);
+
+  DPRINTK(DQDISC, "} delay_drop\n");
+  return out; 
+}
+
+static void
+delay_reset(struct Qdisc* sch)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+
+  DPRINTK(DQDISC, "{ delay_reset\n");
+
+  del_timer( &p->wd_timer );
+  skb_queue_purge(&sch->q);
+  time_node_queue_purge ( &p->times_queue );
+  sch->stats.backlog = 0;
+  qdisc_reset(p->qd);
+  sch->q.qlen = 0;
+
+  DPRINTK(DQDISC, "} delay_reset\n");
+}
+
+static int 
+delay_change(struct Qdisc *sch, struct rtattr *opt)
+{
+  int err = -EINVAL;
+  struct delay_sched_data *p = (void*)sch->data;
+  struct tc_delay_qopt * qopt;
+
+  DPRINTK(DQDISC, "{ delay_change\n");
+
+  qopt = RTA_DATA(opt);
+
+  if ( RTA_PAYLOAD(opt) < sizeof(*qopt) )
+    {
+      EPRINTK("delay_change: opt is too small\n");
+      goto done;
+    }
+
+  DPRINTK(DSTATS, "About to lock tree in change\n");
+  sch_tree_lock(sch);
+  DPRINTK(DSTATS, "Tree locked\n");
+  p->delaytime = qopt->delay_usec;
+  p->reset_time = qopt->reset_time;
+  DPRINTK(DSTATS, "Reseting timer\n");
+  init_timer( &p->wd_timer );
+  p->wd_timer.function = delay_watchdog;
+  p->wd_timer.data = (unsigned long)sch;
+  DPRINTK(DSTATS, "Timer reset\n");
+  sch_tree_unlock(sch);
+  DPRINTK(DSTATS, "Tree unlocked\n");
+
+  DPRINTK(DQDISC, "delay_change: usec: %u\n", qopt->delay_usec);
+
+  err = 0;
+ done:
+  DPRINTK(DQDISC, "} delay_change\n");
+  return err;
+}
+
+static int 
+delay_init(struct Qdisc *sch, struct rtattr *opt)
+{
+  int err = -EINVAL;
+  struct delay_sched_data *p = (void*)sch->data;
+
+  DPRINTK(DQDISC, "{ delay_init\n");
+
+  DPRINTK(DQDISC, ">> initializing queue\n");
+  INIT_LIST_HEAD(&p->times_queue.link);
+  oldbklog = 0; /* XXX: temp */
+
+  if ( delay_change(sch, opt) != 0 )
+    {
+      DPRINTK(DQDISC, ">> delay_change failed\n");
+    }
+  else 
+    {
+      p->filter_list = NULL;
+      if (!(p->qd = qdisc_create_dflt(sch->dev, &pfifo_qdisc_ops)))
+        p->qd = &noop_qdisc;
+
+      DPRINTK(DQDISC | 100, "MOD_INC_USE_COUNT\n");
+      MOD_INC_USE_COUNT;
+      err = 0;
+    }
+
+  DPRINTK(DQDISC, "} delay_init\n");
+  return err;
+}
+
+static 
+void delay_destroy(struct Qdisc *sch)
+{
+  struct delay_sched_data *p = (struct delay_sched_data *)sch->data;
+  struct tcf_proto *tp;
+
+  DPRINTK(DQDISC, "{ delay_destroy\n");
+
+  DPRINTK(DQDISC | 100, ">> del_timer\n");
+
+  del_timer( &p->wd_timer );
+  skb_queue_purge(&sch->q);
+  time_node_queue_purge ( &p->times_queue );
+  sch->stats.backlog = 0;
+
+  while (p->filter_list) {
+    tp = p->filter_list;
+    p->filter_list = tp->next;
+    tp->ops->destroy(tp);
+  }
+
+  qdisc_destroy(p->qd);
+  p->qd = &noop_qdisc;
+
+  sch->q.qlen = 0;
+
+  DPRINTK(DQDISC | 100, ">> DEC_USE_COUNT\n");
+  MOD_DEC_USE_COUNT;
+  DPRINTK(DQDISC, "} delay_destroy\n");
+}
+
+
+static int 
+delay_dump(struct Qdisc *sch, struct sk_buff *skb)
+{
+  struct delay_sched_data *p = (void*)sch->data;
+  unsigned char	 *b = skb->tail;
+  struct tc_delay_qopt opt;
+
+
+  DPRINTK(DQDISC, "{ delay_dump\n");
+
+  sch_tree_lock(sch);
+  opt.delay_usec = p->delaytime;
+  opt.reset_time = p->reset_time;
+  sch_tree_unlock(sch);
+
+  RTA_PUT(skb, TCA_OPTIONS, sizeof(opt), &opt);
+
+  DPRINTK(DQDISC, "} delay_dump\n");
+  return skb->len;
+
+ rtattr_failure:
+  skb_trim(skb, b - skb->data);
+  DPRINTK(DQDISC, "} delay_dump - failed!\n");
+  return -1;
+}
+
+static struct Qdisc_class_ops delay_class_ops =
+{
+  delay_graft,			/* graft */
+  delay_leaf,			/* leaf */
+  delay_get,			/* get */
+  delay_put,			/* put */
+  delay_class_change,		/* change */
+  delay_delete,			/* delete */
+  delay_walk,			/* walk */
+  
+  delay_find_tcf,		/* tcf_chain */
+  delay_bind_filter,		/* bind_tcf */
+  delay_put,			/* unbind_tcf */
+  
+  delay_dump_class,		/* dump */
+};
+
+struct Qdisc_ops delay_qdisc_ops =
+{
+  NULL,
+  &delay_class_ops,
+  "delay",
+  sizeof(struct delay_sched_data),
+
+  delay_enqueue,
+  delay_dequeue,
+  delay_requeue,
+  delay_drop,
+
+  delay_init,
+  delay_reset,
+  delay_destroy,
+  delay_change,
+
+  /* #ifdef CONFIG_RTNETLINK */
+  delay_dump,
+  /* #endif */
+};
+
+#ifdef MODULE
+int init_module ( void )
+{
+  return register_qdisc( &delay_qdisc_ops );
+}
+void cleanup_module ( void )
+{
+  unregister_qdisc( &delay_qdisc_ops );
+}
+
+#endif /* MODULE */
+MODULE_LICENSE("GPL");

--- linux-2.4.20-31.9/net/sched/sch_generic.c	2002-11-28 16:53:16.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/sched/sch_generic.c	2004-08-21 19:28:49.000000000 -0600
@@ -29,6 +29,9 @@
 #include <linux/skbuff.h>
 #include <linux/rtnetlink.h>
 #include <linux/init.h>
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+#include <linux/imq.h>
+#endif
 #include <net/sock.h>
 #include <net/pkt_sched.h>
 
@@ -89,7 +92,11 @@
 			spin_unlock(&dev->queue_lock);
 
 			if (!netif_queue_stopped(dev)) {
-				if (netdev_nit)
+				if (netdev_nit
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+				    && !(skb->imq_flags & IMQ_F_ENQUEUE)
+#endif
+				    )
 					dev_queue_xmit_nit(skb, dev);
 
 				if (dev->hard_start_xmit(skb, dev) == 0) {

--- linux-2.4.20-31.9/net/sched/sch_htb.c	2004-04-13 15:07:12.000000000 -0600
+++ linux-2.4.20-31.9linkdelay/net/sched/sch_htb.c	2004-08-21 19:28:49.000000000 -0600
@@ -805,11 +805,13 @@
 #ifdef HTB_DEBUG
 		if (diff > cl->mbuffer || diff < 0 || PSCHED_TLESS(q->now, cl->t_c)) {
 			if (net_ratelimit())
+			  /* remove for now - need PSCHED_UTIME abstraction
 				printk(KERN_ERR "HTB: bad diff in charge, cl=%X diff=%lX now=%Lu then=%Lu j=%lu\n",
 				       cl->classid, diff,
 				       (unsigned long long) q->now,
 				       (unsigned long long) cl->t_c,
 				       jiffies);
+			  */
 			diff = 1000;
 		}
 #endif
@@ -875,11 +877,13 @@
 #ifdef HTB_DEBUG
 		if (diff > cl->mbuffer || diff < 0 || PSCHED_TLESS(q->now, cl->t_c)) {
 			if (net_ratelimit())
+			  /* another occurance removed.
 				printk(KERN_ERR "HTB: bad diff in events, cl=%X diff=%lX now=%Lu then=%Lu j=%lu\n",
 				       cl->classid, diff,
 				       (unsigned long long) q->now,
 				       (unsigned long long) cl->t_c,
 				       jiffies);
+			  */
 			diff = 1000;
 		}
 #endif

--- linux-2.4.20-31.9/net/sched/sch_plr.c	1969-12-31 17:00:00.000000000 -0700
+++ linux-2.4.20-31.9linkdelay/net/sched/sch_plr.c	2004-08-21 19:28:49.000000000 -0600
@@ -0,0 +1,482 @@
+/*
+ * net/sched/sch_plr.c	probibalistically drop packets
+ *
+ *		This program is free software; you can redistribute it and/or
+ *		modify it under the terms of the GNU General Public License
+ *		as published by the Free Software Foundation; either version
+ *		2 of the License, or (at your option) any later version.
+ *
+ * Authors:	
+ *         Kirk Webb <kwebb@cs.utah.edu>
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/bitops.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/string.h>
+#include <linux/mm.h>
+#include <linux/socket.h>
+#include <linux/sockios.h>
+#include <linux/in.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/if_ether.h>
+#include <linux/inet.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/notifier.h>
+#include <net/ip.h>
+#include <net/route.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <net/pkt_sched.h>
+
+/*  
+    Simple PLR "scheduler" We drop packets based on a uniform
+    probability dist, set within the range of an u32.  The tc tool
+    expects a floating pt. number between 0 and 1, and subsequently
+    scales it to the appropriate closest u32 value (btw 0 and 2^32)
+    before handing it off to this module via rtnetlink.
+ */
+
+#define DQDISC (1<<16)
+#define DCLASS (1<<17)
+
+/* debugging level & bitmask: upper 16 bits are debug mask, lower 16
+   are level */
+/* bits for mask are defined above, and level is 0 - 1000 */
+#define DBG DQDISC | DCLASS | 1000
+
+#if 0
+#define DMSK(lvl) ((lvl) & 0xffff0000)
+#define DLVL(lvl)  ((lvl) & 0x0000ffff)
+#define DPRINTK(lvl, fmt, args...)   if ((DMSK(lvl) & DMSK(DBG)) && \
+                                         (DLVL(lvl) < DLVL(DBG))) \
+                                       { printk(KERN_DEBUG fmt, ##args); }
+#else
+#define DMSK(lvl)
+#define DLVL(lvl)
+#define DPRINTK(lvl, fmt, args...)
+#endif
+
+#define EPRINTK(fmt, args...)    printk(KERN_ERR fmt, ##args);
+
+struct plr_sched_data
+{
+  struct Qdisc        *qd;            /* child qdisc - we only support 1 */
+  struct tcf_proto    *filter_list;   /* packet filter chain - not used */
+  __u32               plr;            /* packet loss rate */
+};
+
+/* ------------------------------------------------------------------------- */
+/* Class functions --------------------------------------------------------- */
+/* ------------------------------------------------------------------------- */
+
+static int 
+plr_graft(struct Qdisc *sch,unsigned long arg, 
+          struct Qdisc *new1,struct Qdisc **old)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+
+  DPRINTK(DCLASS | 100, "plr_graft(sch %p,[qdisc %p],new %p,old %p)\n",
+          sch,p,new1,old);
+  if (!new1)
+    new1 = &noop_qdisc;
+  sch_tree_lock(sch);
+  *old = xchg(&p->qd,new1);
+  if (*old)
+    qdisc_reset(*old);
+  sch_tree_unlock(sch); /* @@@ move up ? */
+  return 0;
+}
+
+
+static struct Qdisc*
+plr_leaf(struct Qdisc *sch, unsigned long arg)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+
+  return p->qd;
+}
+
+
+static unsigned long 
+plr_get(struct Qdisc *sch,u32 classid)
+{
+  struct plr_sched_data *p __attribute__((unused)) = 
+    (struct plr_sched_data *)sch->data;
+
+  DPRINTK(DCLASS | 100, "plr_get(sch %p,[qdisc %p],classid %x)\n",
+          sch,p,classid);
+  return 1; /* we currently only support one class so.. */
+}
+
+static int
+plr_class_change(struct Qdisc *sch, u32 classid, u32 parent,
+                 struct rtattr **tca, unsigned long *arg)
+{
+  return 0;
+}
+
+static unsigned long 
+plr_bind_filter(struct Qdisc *sch, unsigned long parent, u32 classid)
+{
+  return plr_get(sch,classid);
+}
+
+
+static void 
+plr_put(struct Qdisc *sch, unsigned long cl)
+{
+}
+
+static int 
+plr_delete(struct Qdisc *sch,unsigned long arg)
+{
+  struct plr_sched_data *p __attribute__((unused)) = 
+    (struct plr_sched_data *)sch->data;
+  
+  if (!arg)
+    return -EINVAL;
+  
+  return 0;
+}
+
+
+static void 
+plr_walk(struct Qdisc *sch,struct qdisc_walker *walker)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  
+  DPRINTK(DCLASS | 100, "plr_walk(sch %p,[qdisc %p],walker %p)\n",
+          sch,p,walker);
+  
+  if (walker->stop)
+    return;
+  
+  if (walker->count >= walker->skip) {
+    if (walker->fn(sch, 1, walker) < 0) {
+      walker->stop = 1;
+    }
+  }
+  else {
+    walker->count++;
+  }
+}
+
+
+static struct tcf_proto**
+plr_find_tcf(struct Qdisc *sch,unsigned long cl)
+{
+	struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+
+	return &p->filter_list;
+}
+
+
+static int 
+plr_dump_class(struct Qdisc *sch, unsigned long cl, 
+               struct sk_buff *skb, struct tcmsg *tcm)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  unsigned char *b = skb->tail;
+  
+  DPRINTK(DCLASS | 100, "plr_dump_class(sch %p,[qdisc %p],class %ld\n",
+          sch,p,cl);
+  tcm->tcm_handle = TC_H_MAKE(TC_H_MAJ(sch->handle),1);
+  RTA_PUT(skb,TCA_OPTIONS,0,NULL);
+
+  return skb->len;
+  
+ rtattr_failure:
+  skb_trim(skb,b-skb->data);
+  return -1;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/* Qdisc functions --------------------------------------------------------- */
+/* ------------------------------------------------------------------------- */
+
+static int
+plr_enqueue(struct sk_buff *skb, struct Qdisc* sch)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  int ret = NET_XMIT_SUCCESS;
+
+  DPRINTK(DQDISC, "{ plr_enqueue\n");
+
+  {
+    __u32 rnd = net_random();
+    psched_time_t currtime;
+
+    PSCHED_GET_TIME(currtime);
+    DPRINTK(DQDISC | 100, "Enqueueing at: %llu\n", currtime);
+
+    if ( rnd < p->plr) 
+      {
+        /* 
+           Drop, but don't tell the network device we did.
+           Keep track though in stats. 
+        */
+	DPRINTK(DQDISC | 200, "Dropped incoming packet, rand val: %u\n", rnd);
+	kfree_skb(skb);
+	sch->stats.drops++;
+        ret = NET_XMIT_DROP;
+      }
+
+    else 
+      {
+        if ((ret = p->qd->ops->enqueue(skb,p->qd)) != 0) {
+          sch->stats.drops++;
+          return ret;
+        }
+        sch->q.qlen++;
+      }
+    
+    /* XXX: where should these go? */
+    sch->stats.bytes += skb->len;
+    sch->stats.packets++;
+  }
+
+  DPRINTK(DQDISC, "} plr_enqueue\n");
+
+  return ret;
+}
+
+static int
+plr_requeue(struct sk_buff *skb, struct Qdisc* sch)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  int out = 0;
+
+  DPRINTK(DQDISC, "{ plr_requeue\n");
+
+  if ((out = p->qd->ops->requeue(skb, p->qd)) == 0) {
+    sch->q.qlen++;
+  }
+  else {
+    sch->stats.drops++;
+  }
+
+  DPRINTK(DQDISC, "} plr_requeue\n");
+
+  return out;
+}
+
+static struct sk_buff *
+plr_dequeue(struct Qdisc* sch)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  struct sk_buff *skb = NULL;
+  psched_time_t currtime;
+
+  DPRINTK(DQDISC, "{ plr_dequeue\n");
+
+  PSCHED_GET_TIME(currtime);
+
+  // dequeue the skb
+  DPRINTK(DQDISC | 200, "time %llu, dequeuing\n", currtime);
+  skb = p->qd->ops->dequeue(p->qd);
+  if ( skb ) 
+    {
+      sch->q.qlen--;
+    }
+	       
+  DPRINTK(DQDISC, "} plr_dequeue\n");
+  return skb;
+}
+
+
+static int
+plr_drop(struct Qdisc* sch)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  int out = 0;
+
+  DPRINTK(DQDISC, "{ plr_drop\n");
+
+  if ((out = p->qd->ops->drop(p->qd)) == 1) {
+    /* sch->stats.drops++;  XXX: should we report a drop too? */
+    sch->q.qlen--;
+  }
+
+  DPRINTK(DQDISC, "} plr_drop\n");
+  return out; 
+}
+
+static void
+plr_reset(struct Qdisc* sch)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+
+  DPRINTK(DQDISC, "{ plr_reset\n");
+
+  qdisc_reset(p->qd);
+  sch->q.qlen = 0;
+
+  DPRINTK(DQDISC, "} plr_reset\n");
+}
+
+static int 
+plr_change(struct Qdisc *sch, struct rtattr *opt)
+{
+  int err = -EINVAL;
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  struct tc_plr_qopt *qopt;
+
+  DPRINTK(DQDISC, "{ plr_change\n");
+
+  qopt = RTA_DATA(opt);
+
+  if ( RTA_PAYLOAD(opt) < sizeof(__u32) )
+    {
+      EPRINTK("plr_change: opt is too small\n");
+      goto done;
+    }
+
+  sch_tree_lock(sch);
+  p->plr = qopt->plr;
+  sch_tree_unlock(sch);
+
+  DPRINTK(DQDISC | 100, "plr_change: plr: %u\n", qopt->plr );
+
+  err = 0;
+ done:
+  DPRINTK(DQDISC, "} plr_change\n");
+  return err;
+}
+
+static int 
+plr_init(struct Qdisc *sch, struct rtattr *opt)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  int err = -EINVAL;
+
+  DPRINTK(DQDISC, "{ plr_init\n");
+
+  if ( plr_change(sch, opt) != 0 )
+    {
+      DPRINTK(DQDISC, ">> plr_change failed\n");
+    }
+
+  else 
+    {
+      p->filter_list = NULL;
+      if (!(p->qd = qdisc_create_dflt(sch->dev, &pfifo_qdisc_ops)))
+        p->qd = &noop_qdisc;
+
+      DPRINTK(DQDISC | 100, "MOD_INC_USE_COUNT\n");
+      MOD_INC_USE_COUNT;
+      err = 0;
+    }
+
+  DPRINTK(DQDISC | 100, "} plr_init\n");
+  return err;
+}
+
+static void 
+plr_destroy(struct Qdisc *sch)
+{
+  struct plr_sched_data *p = (struct plr_sched_data *)sch->data;
+  struct tcf_proto *tp;
+
+  DPRINTK(DQDISC, "{ plr_destroy\n");
+
+  while (p->filter_list) {
+    tp = p->filter_list;
+    p->filter_list = tp->next;
+    tp->ops->destroy(tp);
+  }
+
+  qdisc_destroy(p->qd);
+  p->qd = &noop_qdisc;
+
+  sch->q.qlen = 0;
+
+  DPRINTK(DQDISC | 100, ">> DEC_USE_COUNT\n");
+  MOD_DEC_USE_COUNT;
+
+  DPRINTK(DQDISC, "} plr_destroy\n");
+}
+
+
+static int 
+plr_dump(struct Qdisc *sch, struct sk_buff *skb)
+{
+  struct plr_sched_data *p = (void*)sch->data;
+  unsigned char	 *b = skb->tail;
+  struct tc_plr_qopt opt;
+
+  DPRINTK(DQDISC, "{ plr_dump\n");
+
+  sch_tree_lock(sch);
+  opt.plr = p->plr;
+  sch_tree_unlock(sch);
+
+  RTA_PUT(skb, TCA_OPTIONS, sizeof(opt), &opt);
+
+  DPRINTK(DQDISC, "} plr_dump\n");
+  return skb->len;
+
+ rtattr_failure:
+  skb_trim(skb, b - skb->data);
+  DPRINTK(DQDISC, "} plr_dump (failed!)\n");
+  return -1;
+}
+
+static struct Qdisc_class_ops plr_class_ops =
+{
+  plr_graft,			/* graft */
+  plr_leaf,			/* leaf */
+  plr_get,			/* get */
+  plr_put,			/* put */
+  plr_class_change,		/* change */
+  plr_delete,			/* delete */
+  plr_walk,			/* walk */
+  
+  plr_find_tcf,		        /* tcf_chain */
+  plr_bind_filter,		/* bind_tcf */
+  plr_put,			/* unbind_tcf */
+  
+  plr_dump_class,		/* dump */
+};
+
+
+struct Qdisc_ops plr_qdisc_ops =
+{
+  NULL,
+  &plr_class_ops,
+  "plr",
+  sizeof(struct plr_sched_data),
+
+  plr_enqueue,
+  plr_dequeue,
+  plr_requeue,
+  plr_drop,
+
+  plr_init,
+  plr_reset,
+  plr_destroy,
+  plr_change,
+
+  plr_dump,
+};
+
+#ifdef MODULE
+int init_module ( void )
+{
+  return register_qdisc( &plr_qdisc_ops );
+}
+void cleanup_module ( void )
+{
+  unregister_qdisc( &plr_qdisc_ops );
+}
+#endif /* MODULE */
+MODULE_LICENSE("GPL");
